# ğŸ¤– Semantic Data Pipeline Agent

> AI-powered semantic extraction pipeline - transforms unstructured text into structured data using Pydantic AI & Google Gemini

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Pydantic AI](https://img.shields.io/badge/pydantic--ai-0.0.15+-green.svg)](https://ai.pydantic.dev/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ¯ Why This Project?

**Traditional validators reject bad data. This tool extracts meaning from it.**

Most data pipelines fail when encountering incomplete records. This CLI tool uses an **AI agent** to perform **semantic extraction** - extracting structured fields (country codes, industries, contract values) from unstructured natural language text.

Perfect for:
- ğŸ¢ Sales lead enrichment from CRM notes
- ğŸŒ Geographic entity extraction
- ğŸ’° Multi-currency data normalization
- ğŸ”§ Unstructured data transformation

---

## âœ¨ Features

- **Semantic Extraction** - AI extracts structured data from unstructured text
- **Geographic Intelligence** - Maps cities to ISO country codes (Parisâ†’FR, Tokyoâ†’JP)
- **Currency Conversion** - Handles EUR, GBP, JPY, AUD with automatic USD conversion
- **Industry Classification** - Categorizes businesses from descriptions
- **Type-Safe AI** - Pydantic AI ensures structured outputs with full validation
- **Beautiful Terminal UI** - Rich tables showing extraction results with confidence scores
- **Rate Limit Protection** - Exponential backoff + inter-row delays handle API limits

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/semantic-data-pipeline-agent.git
cd semantic-data-pipeline-agent

# Install with pip
pip install -e .

# Set up API key
cp .env.example .env
# Edit .env and add your GOOGLE_API_KEY
```

### Usage

```bash
# Generate sample dataset with semantic extraction challenges
pipeline generate --size 30

# Run the semantic extraction pipeline
pipeline clean examples/sample_leads.csv

# View results
cat outputs/valid.json      # Records passing validation
cat outputs/repaired.json   # AI-extracted records
cat outputs/failed.json     # Unrepairable records
```

---

## ğŸ“Š Example Output

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  Semantic Data Pipeline Agent             â”‚
â”‚  AI-Powered Semantic Extraction           â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Processing: examples/sample_leads.csv
Mode: Semantic Extraction Pipeline (Validate â†’ Extract â†’ Report)

                          PIPELINE RESULTS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Category             â”ƒ      Count â”ƒ   Percentage â”ƒ Status                   â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ âœ“ Valid              â”‚         12 â”‚        40.0% â”‚ Passed strict validation â”‚
â”‚ âš™ Repaired by AI     â”‚          6 â”‚        20.0% â”‚ Semantic extraction      â”‚
â”‚ âœ— Failed             â”‚         12 â”‚        40.0% â”‚ Unrepairable records     â”‚
â”‚ TOTAL PROCESSED      â”‚         30 â”‚       100.0% â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                          SEMANTIC EXTRACTION EXAMPLES
â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ ID  â”ƒ Input Note                                                    â”ƒ Country  â”ƒ Industry   â”ƒ Value (USD)  â”ƒ Confidence â”ƒ
â”¡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ 16  â”‚ London hospital administrator interested in medical records   â”‚ GB       â”‚ Healthcare â”‚ $104,000     â”‚ 90.0%      â”‚
â”‚     â”‚ system. Budget: 80,000 GBP.                                   â”‚          â”‚            â”‚              â”‚            â”‚
â”‚ 17  â”‚ Berlin boutique owner. Small fashion e-commerce platform      â”‚ DE       â”‚ Retail     â”‚ $16,500      â”‚ 90.0%      â”‚
â”‚     â”‚ needed. Budget: 15k EUR.                                      â”‚          â”‚            â”‚              â”‚            â”‚
â”‚ 21  â”‚ E-commerce store in New York. Small team needs inventory      â”‚ US       â”‚ Retail     â”‚ $18,000      â”‚ 90.0%      â”‚
â”‚     â”‚ system for $18k.                                              â”‚          â”‚            â”‚              â”‚            â”‚
â”‚ 22  â”‚ Meeting with Tokyo startup. Developing fintech app. Seed      â”‚ JP       â”‚ Finance    â”‚ $56,000      â”‚ 90.0%      â”‚
â”‚     â”‚ funded: 8 million Yen budget.                                 â”‚          â”‚            â”‚              â”‚            â”‚
â”‚ 23  â”‚ Investment bank in the City of London. Trading platform       â”‚ GB       â”‚ Finance    â”‚ $325,000     â”‚ 90.0%      â”‚
â”‚     â”‚ upgrade: 250k GBP.                                            â”‚          â”‚            â”‚              â”‚            â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Architecture

### Pipeline Flow

```
CSV Input â†’ Strict Validation â†’ Semantic Extraction â†’ Structured Output
              â†“ Pass                  â†“ Pass               â†“
           valid.json            repaired.json       failed.json
```

### Tech Stack

- **Pydantic AI** - Type-safe LLM agents with structured outputs
- **Google Gemini 2.5 Flash Lite** - Fast, cost-effective semantic extraction
- **Pydantic V2** - Runtime validation with optional fields
- **Typer + Rich** - Professional CLI with beautiful terminal UI

---

## ğŸ§  Semantic Extraction Capabilities

### 1. Geographic Extraction
Maps city names and contextual clues to ISO 3166-1 alpha-2 country codes:
- **Cities:** Parisâ†’FR, Tokyoâ†’JP, Londonâ†’GB, Berlinâ†’DE, New Yorkâ†’US
- **Context:** "Silicon Valley"â†’US, "City of London"â†’GB, "Mizuho Bank"â†’JP

### 2. Currency Conversion
Detects foreign currencies and converts to USD:
- **EUR:** Ã—1.10 (5000 EUR â†’ $5,500)
- **GBP:** Ã—1.30 (80,000 GBP â†’ $104,000)
- **JPY:** Ã—0.007 (8M Yen â†’ $56,000)
- **AUD:** Ã—0.65 (200k AUD â†’ $130,000)
- Handles variations: "5k", "$150k", "5 million"

### 3. Industry Classification
Categorizes businesses from keywords into structured enums:
- **Tech:** software, AI, cloud, SaaS, startup, platform
- **Finance:** bank, investment, trading, insurance, fintech
- **Retail:** bakery, shop, store, e-commerce, boutique
- **Healthcare:** hospital, clinic, pharma, medical

### 4. Segment Inference
Determines customer segment from context:
- **Enterprise:** $100k+ contracts, "Fortune 500", "multi-site"
- **Mid-Market:** $25k-$99k contracts
- **SMB:** <$25k contracts, "startup", "small team"

### 5. Confidence Scoring
AI assigns confidence scores (0.0-1.0) based on inference certainty:
- **1.0:** All fields explicitly stated
- **0.8-0.9:** Strong contextual evidence
- **0.6-0.7:** Reasonable inference
- **0.4-0.5:** Weak signals, uncertain

---

## ğŸ” Why Pydantic AI?

Unlike raw LLM APIs, Pydantic AI enforces **type safety on AI outputs**:

```python
# Without Pydantic AI - hope the LLM returns valid JSON
response = llm.generate("Extract data: ...")
data = json.loads(response)  # âŒ Might crash

# With Pydantic AI - guaranteed type safety
result = agent.run_sync("Extract data: ...")
lead: SalesLead = result.output  # âœ… Type-safe, validated
```

The agent MUST return a valid `SalesLead` object or raise an error. No surprises.

---

## ğŸ“ Schema Example

```python
class Industry(str, Enum):
    TECH = "Tech"
    FINANCE = "Finance"
    RETAIL = "Retail"
    HEALTHCARE = "Healthcare"
    OTHER = "Other"

class SalesLead(BaseModel):
    # Required fields
    id: int                              # Positive integer
    name: str                            # Title Case validated
    email: EmailStr                      # RFC 5322 compliant

    # Optional (can be inferred from sales_notes)
    country_code: Optional[str]          # ISO alpha-2 (^[A-Z]{2}$)
    industry: Optional[Industry]         # Enum
    segment: Optional[Segment]           # Enum
    contract_value: Optional[float]      # Positive USD amount

    # Semantic inference fields
    sales_notes: Optional[str]           # Unstructured input
    confidence_score: float = 1.0        # 0.0-1.0
```

**Key Feature:** If `sales_notes` is present but fields are missing, triggers AI semantic extraction (enforced by `model_post_init` validator).

---

## ğŸ“ Learning Outcomes

This project demonstrates:

1. **Semantic NLP** - Entity extraction, currency conversion, contextual reasoning
2. **Modern Python** - 3.11+, type hints, pyproject.toml
3. **Pydantic AI agents** - Type-safe structured outputs
4. **Data validation** - Optional fields, custom validators
5. **Production patterns** - Rate limiting, exponential backoff, error handling
6. **Professional CLI** - Typer + Rich with beautiful UX

---

## ğŸ› ï¸ Project Structure

```
semantic-data-pipeline-agent/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ semantic_pipeline/
â”‚       â”œâ”€â”€ __init__.py        # Package initialization
â”‚       â”œâ”€â”€ schemas.py         # Pydantic models with Industry enum
â”‚       â”œâ”€â”€ agent.py           # Gemini agent with retry logic
â”‚       â”œâ”€â”€ processor.py       # Pipeline with rate limiting
â”‚       â”œâ”€â”€ generator.py       # Sample data generator
â”‚       â””â”€â”€ cli.py             # CLI commands
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ sample_leads.csv       # Generated test data
â”œâ”€â”€ outputs/                   # Pipeline results
â”‚   â”œâ”€â”€ valid.json
â”‚   â”œâ”€â”€ repaired.json
â”‚   â””â”€â”€ failed.json
â”œâ”€â”€ pyproject.toml             # Modern Python packaging
â”œâ”€â”€ README.md
â”œâ”€â”€ CLAUDE.md                  # Developer guide
â”œâ”€â”€ LICENSE
â””â”€â”€ .env.example
```

---

## ğŸ“ˆ Sample Data Distribution

The generated dataset includes:

**40% Valid Records** - Complete data passing validation:
- All fields populated with valid values
- No semantic extraction needed

**50% Incomplete Records** - Requires semantic extraction:
- Missing fields but rich `sales_notes` with context
- Examples: "Meeting in Paris with bakery owner. Budget: 5000 EUR"
- AI extracts: FR, Retail, $5,500, 0.9 confidence

**10% Unfixable Records** - Cannot be repaired:
- Empty names or invalid emails
- Vague notes without useful context
- Truly incomplete data

---

## ğŸ”§ Advanced Features

### Rate Limiting Protection

**Two-layer strategy to handle API limits:**

1. **Exponential Backoff** (agent.py)
   - Max 3 retries per record
   - Wait times: 2s â†’ 4s â†’ 8s
   - Only retries on 503/overloaded errors

2. **Inter-Row Delay** (processor.py)
   - 1.0s delay between each extraction
   - Prevents rapid-fire API requests
   - Configurable via `DataProcessor(delay_between_repairs=X)`

**Trade-off:** Slower processing (up to 15s per problematic record) vs higher success rate

---

## ğŸ¤ Contributing

Contributions welcome! This is a portfolio project demonstrating modern Python and AI best practices.

Areas for improvement:
- Async processing with `agent.run()` for large datasets
- Unit tests with pytest + mock API
- Expose `delay_between_repairs` as CLI option
- Support more country variations (full names)
- Repair statistics dashboard

---

## ğŸ“„ License

MIT Â© 2026 Semantic Data Pipeline Agent Contributors

See [LICENSE](LICENSE) file for details.

---

## ğŸ”— Links

- **Pydantic AI Documentation**: https://ai.pydantic.dev/
- **Google Gemini API**: https://ai.google.dev/
- **Pydantic V2**: https://docs.pydantic.dev/
- **Typer**: https://typer.tiangolo.com/
- **Rich**: https://rich.readthedocs.io/

---

## ğŸ™ Acknowledgments

Built with:
- [Pydantic AI](https://ai.pydantic.dev/) - Type-safe AI agents
- [Google Gemini](https://ai.google.dev/) - Semantic extraction model
- [Pydantic](https://docs.pydantic.dev/) - Data validation
- [Typer](https://typer.tiangolo.com/) - CLI framework
- [Rich](https://rich.readthedocs.io/) - Terminal formatting

---

**Made with â¤ï¸ for the AI & data engineering community**
