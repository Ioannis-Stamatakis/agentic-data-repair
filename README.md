# ğŸ¤– Agentic Data Repair

> A self-healing data pipeline powered by Pydantic AI & Google Gemini

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Pydantic AI](https://img.shields.io/badge/pydantic--ai-0.0.15+-green.svg)](https://ai.pydantic.dev/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ¯ Why This Project?

**Traditional validators reject bad data. This tool *fixes* it.**

Most data pipelines fail when encountering invalid records. This CLI tool uses an **AI agent** to understand validation errors and intelligently repair data, ensuring 100% schema compliance.

Perfect for:
- ğŸ¢ Sales lead normalization
- ğŸŒ International data cleanup
- ğŸ“Š ETL pipeline resilience
- ğŸ”§ Legacy data migration

---

## âœ¨ Features

- **Strict Pydantic V2 Validation** - Zero tolerance for bad data
- **AI-Powered Repair** - Gemini 2.5 Flash understands and fixes errors
- **Intelligent Normalization**:
  - Country names â†’ ISO codes ("United States" â†’ "US")
  - Name formatting â†’ Title Case ("john smith" â†’ "John Smith")
  - Segment inference from contract value
  - Currency cleanup ("$10,000" â†’ 10000.0)
- **Beautiful Terminal UI** - Rich tables and progress bars
- **Type-Safe** - Full Python type hints with modern best practices

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/agentic-data-repair.git
cd agentic-data-repair

# Install with pip
pip install -e .

# Set up API key
cp .env.example .env
# Edit .env and add your GOOGLE_API_KEY
```

### Usage

```bash
# Generate sample dataset (50 records: 30 clean, 15 fixable, 5 unfixable)
data-repair generate

# Run the repair pipeline
data-repair clean examples/sample_leads.csv

# View results
cat outputs/valid.json      # Clean records
cat outputs/repaired.json   # AI-fixed records
cat outputs/failed.json     # Unrepairable records
```

---

## ğŸ“Š Example Output

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  Agentic Data Repair                â”‚
â”‚  AI-Powered Data Quality Pipeline   â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Processing: examples/sample_leads.csv

        Processing Results
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Status       â”ƒ Count â”ƒ Description          â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ âœ“ Valid      â”‚    30 â”‚ Passed validation    â”‚
â”‚ âš™ Repaired   â”‚    15 â”‚ Fixed by AI agent    â”‚
â”‚ âœ— Failed     â”‚     5 â”‚ Unrepairable         â”‚
â”‚ Total        â”‚    50 â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Success Rate: 90.0%
Results saved to outputs/
```

---

## ğŸ—ï¸ Architecture

### Pipeline Flow

```
CSV Input â†’ Strict Validation â†’ AI Repair â†’ Structured Output
              â†“ Pass                â†“ Pass        â†“
           valid.json          repaired.json   failed.json
```

### Tech Stack

- **Pydantic AI** - Type-safe LLM agents with structured outputs
- **Google Gemini 2.5 Flash** - Fast, cost-effective AI model
- **Pydantic V2** - Runtime validation with strict mode
- **Typer + Rich** - Professional CLI with beautiful terminal UI

---

## ğŸ” Why Pydantic AI?

Unlike raw LLM APIs, Pydantic AI enforces **type safety on AI outputs**:

```python
# Without Pydantic AI - hope the LLM returns valid JSON
response = llm.generate("Fix this data: ...")
data = json.loads(response)  # âŒ Might crash

# With Pydantic AI - guaranteed type safety
result = agent.run_sync("Fix this data: ...")
lead: SalesLead = result.data  # âœ… Type-safe, validated
```

The agent MUST return a valid `SalesLead` object or raise an error. No surprises.

---

## ğŸ“ Schema Example

```python
class SalesLead(BaseModel):
    id: int                           # Positive integer
    name: str                         # Title Case required
    email: EmailStr                   # Valid email format
    country_code: str                 # ISO 3166-1 alpha-2 (e.g., "US")
    segment: Segment                  # Enum: Enterprise/Mid-Market/SMB
    contract_value: float             # Positive currency value
```

**Strict Validation Rules:**
- Names must be in Title Case (enforced by custom validator)
- Country codes must be exactly 2 uppercase letters
- Emails must pass RFC 5322 validation
- Contract values must be positive
- Segments must match enum exactly

---

## ğŸ“ Learning Outcomes

This project demonstrates:

1. **Modern Python** (3.11+, type hints, pyproject.toml)
2. **Pydantic AI agents** with structured outputs
3. **Strict data validation** with Pydantic V2
4. **Professional CLI design** with Typer + Rich
5. **Production patterns** (error handling, logging, file I/O)

---

## ğŸ› ï¸ Project Structure

```
agentic-data-repair/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ data_repair/
â”‚       â”œâ”€â”€ __init__.py        # Package initialization
â”‚       â”œâ”€â”€ schemas.py         # Pydantic models
â”‚       â”œâ”€â”€ agent.py           # Pydantic AI agent
â”‚       â”œâ”€â”€ processor.py       # Data pipeline
â”‚       â”œâ”€â”€ generator.py       # Sample data generator
â”‚       â””â”€â”€ cli.py             # CLI commands
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ sample_leads.csv       # Generated test data
â”œâ”€â”€ outputs/                   # Pipeline results
â”‚   â”œâ”€â”€ valid.json
â”‚   â”œâ”€â”€ repaired.json
â”‚   â””â”€â”€ failed.json
â”œâ”€â”€ pyproject.toml             # Modern Python packaging
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ .env.example
```

---

## ğŸ“ˆ Sample Data Distribution

The generated dataset includes:

**30 Clean Records** - Perfect data that passes validation:
- Valid ISO country codes (US, GB, DE, FR, JP, AU, CA, ES)
- Names in proper Title Case
- Valid email addresses
- Correct segment enums
- Positive contract values

**15 Fixable Records** - Issues the AI can repair:
- Country variations: "USA", "usa", "United States", "UK", "germany"
- Name case issues: "alice cooper", "BOB MARLEY"
- Segment variations: "small business", "enterprise"
- Contract formatting: "$45,000", "$200,000.00"

**5 Unfixable Records** - Data that cannot be repaired:
- Empty names
- Invalid email formats
- Negative contract values
- Invalid country codes (ZZZ)
- Missing critical data

---

## ğŸ”§ Advanced Usage

### Custom Output Directory

```bash
data-repair clean input.csv --output custom_results/
```

### Generate Custom Dataset

```bash
data-repair generate --output my_test_data.csv
```

### Environment Variables

```bash
# Set API key directly
export GOOGLE_API_KEY="your_api_key_here"

# Or use .env file
echo "GOOGLE_API_KEY=your_api_key_here" > .env
```

---

## ğŸ¤ Contributing

Contributions are welcome! This is a portfolio project designed to demonstrate modern Python and AI best practices.

Areas for improvement:
- Add unit tests with pytest
- Implement async processing for large datasets
- Add confidence scores for repairs
- Support more country code variations
- Add repair statistics and metrics

---

## ğŸ“„ License

MIT Â© 2026 Agentic Data Repair Contributors

See [LICENSE](LICENSE) file for details.

---

## ğŸ”— Links

- **Pydantic AI Documentation**: https://ai.pydantic.dev/
- **Google Gemini API**: https://ai.google.dev/
- **Pydantic V2**: https://docs.pydantic.dev/
- **Typer**: https://typer.tiangolo.com/
- **Rich**: https://rich.readthedocs.io/

---

## ğŸ™ Acknowledgments

Built with:
- [Pydantic AI](https://ai.pydantic.dev/) - Type-safe AI agents
- [Google Gemini](https://ai.google.dev/) - Powerful language model
- [Pydantic](https://docs.pydantic.dev/) - Data validation
- [Typer](https://typer.tiangolo.com/) - CLI framework
- [Rich](https://rich.readthedocs.io/) - Terminal formatting

---

**Made with â¤ï¸ for the data engineering community**
